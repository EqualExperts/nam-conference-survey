# Interview: Andrew Shawcare

**Date:** 2025-11-13 (11:30)
**Interviewer:** Mike Mitchell
**Persona:** Equal Experts consultant attending December conference

## Participant Background
- **Role**: Consultant at Equal Experts
- **Experience**: Attended AI workshop in India with survey experience
- **Company/Context**: Equal Experts consultancy, participates in company conferences and events, plays dodgeball on Thursdays with team coordination needs

## Pain Points and Problem Areas

### 1. Survey Black Hole Effect
- **Description**: "It's just a black hole. You send it down the pipe. And it's unclear what happens to the survey or whether it was worth your time filling it out."
- **Context**: After completing any survey, particularly post-event feedback
- **Frequency**: General experience with surveys
- **Impact**:
  - Severity: High
  - Consequences: Time wasted, lack of closure, questioning value of participation
  - Emotional impact: Feels inauthentic, uncertain about purpose
- **Current Workaround**: Only completes surveys when no other feedback option exists
- **What They're Really Trying to Do**: Provide meaningful feedback that creates actual change

### 2. Inauthentic Survey Experience
- **Description**: "I want to skip surveys because I feel somewhat inauthentic. In some way. And I think my only motivation is that seems the path if there's no other option to give feedback."
- **Context**: When asked to complete surveys after events
- **Frequency**: General pattern with most surveys
- **Impact**:
  - Severity: Medium
  - Consequences: Reduced participation, skepticism about organiser intentions
  - Emotional impact: Feels like going through motions rather than genuine feedback
- **Current Workaround**: Only participates "if there's no other option to give feedback"
- **What They're Really Trying to Do**: Engage in authentic feedback exchange where intentions are clear

### 3. Mobile Device Limitation for Long-Form Responses
- **Description**: Mobile input modality not suitable for thoughtful, detailed open-ended responses
- **Context**: When surveys contain open-ended questions but only mobile access available
- **Frequency**: When forced to use phone for detailed feedback
- **Impact**:
  - Severity: Medium
  - Consequences: Shortened responses, reduced quality feedback
  - Emotional impact: Frustration with input method
- **Current Workaround**: Prefers computer for long-form, mobile only for multiple choice
- **What They're Really Trying to Do**: Provide detailed, thoughtful responses using appropriate input method

### 4. Unclear Survey Intention vs Personal Motivation Mismatch
- **Description**: Frustration when survey purpose isn't communicated upfront, making it unclear whether feedback is genuinely wanted or procedural
- **Context**: Beginning survey without knowing if it's for organisers' benefit or genuine feedback collection
- **Frequency**: Most survey experiences
- **Impact**:
  - Severity: Medium
  - Consequences: Wrong expectations, inappropriate response style, potential abandonment
  - Emotional impact: Confusion about how to respond appropriately
- **Current Workaround**: Makes assumptions about survey purpose during completion
- **What They're Really Trying to Do**: Align response style with actual survey purpose and value

## Unmet Needs

### 1. Transparent Communication About Data Usage
- **Need Statement**: Clear explanation of how each survey question's data will be used
- **Context**: Before beginning survey completion
- **Type of Need**: Quality requirement (defines what "good" looks like)
- **Associated with Pain?**: Yes → Solving inauthentic survey experience
- **Priority**: Must-have for meaningful participation
- **Success Criteria**: "For each question, there was, let's say, subtext underneath saying," what the data will be used for

### 2. Action-Based Follow-Up Communication
- **Need Statement**: Information about actions taken as result of survey responses
- **Context**: After survey data has been processed and decisions made
- **Type of Need**: Emotional need (closure and validation)
- **Associated with Pain?**: Yes → Addressing black hole effect
- **Priority**: High priority for continued participation
- **Success Criteria**: "We read it and we did this as a result of it" or response-based actions

### 3. Medium Continuity for Survey Communication
- **Need Statement**: Consistent communication channel from survey invitation through results sharing
- **Context**: Entire survey lifecycle from invitation to follow-up
- **Type of Need**: Quality requirement
- **Associated with Pain?**: No → Enabling organised, coherent experience
- **Priority**: Nice-to-have but important for professional experience
- **Success Criteria**: "Having continuity of what the survey was, so I had the invite" through the same channel/sender

### 4. Question-Level Skip Capability
- **Need Statement**: Ability to skip individual questions while continuing survey
- **Context**: When personal values conflict with specific question purposes
- **Type of Need**: Enabling capability
- **Associated with Pain?**: No → Enabling selective participation
- **Priority**: Must-have for comfort with participation
- **Success Criteria**: "I would potentially want to just not do that question" without abandoning entire survey

### 5. Before-Conference-End Completion Window
- **Need Statement**: Survey completion while still at event location with fresh experience
- **Context**: Conference feedback collection timing
- **Type of Need**: Constraint/Requirement
- **Associated with Pain?**: No → Optimising feedback quality
- **Priority**: Must-have for authentic responses
- **Success Criteria**: Complete before attendees leave venue and emotions/thoughts fade

## Aspirations & Opportunities

### 1. Event Retrospective Discussion Format
- **Aspiration**: "Do a retro with the attendees at the very end and to devote time" to discussion-based feedback
- **Inspiration Source**: Agile methodology practices applied to conference feedback
- **Why It Excites Them**: Most authentic way to gather feedback, allows discussion and building on others' responses
- **Uncertainty/Questions**: Whether time and format constraints allow for this approach
- **Exploration vs Commitment**: High interest, sees as ideal solution
- **Quote**: "If you really wanted it. It would be the most authentic way to get it"

### 2. Sticky Notes on Wall Feedback Method
- **Aspiration**: Physical, collaborative feedback collection using sticky notes
- **Inspiration Source**: Traditional workshop facilitation techniques
- **Why It Excites Them**: Enables relationship of discussion rather than isolated responses
- **Uncertainty/Questions**: Practicality for remote or large-scale events
- **Exploration vs Commitment**: Ideal preference, acknowledges practical limitations
- **Quote**: "The bias answer would be stickies on a wall. Because it would be" collaborative

### 3. Curated Group Survey Discussion
- **Aspiration**: Completing surveys as group activity with shared discussion
- **Inspiration Source**: Combining individual reflection with collective insight
- **Why It Excites Them**: "Listen to the answers of others and to have a discussion around" them
- **Uncertainty/Questions**: How to structure for maximum benefit
- **Exploration vs Commitment**: Strong interest as compromise between individual surveys and full retrospective

## Current Workflow: Conference Feedback Provision

**Trigger**: Receiving survey request after attending conference or workshop

**Goal**: Provide useful feedback to improve future events

**Steps**:

1. **Receive survey invitation** (typically via email after event)
   - Actions: Check email and notice survey request
   - Tools/systems: Email client
   - Decision points: Is this worth my time?

2. **Assess survey purpose** (try to determine if feedback is genuinely wanted or procedural)
   - Actions: Read invitation message, gauge tone and intent
   - Tools/systems: Email content
   - Decision points: Does this feel authentic or performative?
   - Friction points: Often unclear what organizers actually want

3. **Evaluate personal motivation** (decide if feedback is worth sharing and no other channel available)
   - Actions: Consider if there are other ways to provide feedback
   - Decision points: Is survey the only option? Do I have meaningful input?
   - Friction points: Lack of alternative feedback channels

4. **Choose device based on question types** (computer for long-form, mobile for multiple choice)
   - Actions: Decide whether to complete on phone or wait for computer access
   - Tools/systems: Phone or computer
   - Decision points: What types of questions will this have?
   - Friction points: Mobile not suitable for detailed responses

5. **Complete survey** (provide responses based on perceived purpose)
   - Actions: Answer questions
   - Tools/systems: Survey platform
   - Friction points: Unclear question purpose, forced responses, inappropriate medium

6. **Submit and forget** (no expectation of follow-up or results)
   - Actions: Click submit
   - Completion Criteria: Survey submitted, regardless of confidence in its value
   - Friction points: Black hole feeling, no closure

**Variations**: Will skip entirely if other feedback channels exist or if survey feels purely procedural

**Pain Points in Workflow**: Uncertainty about purpose, black hole effect, device limitations

**What's Missing**: Clear communication about data usage, follow-up on actions taken, alternative feedback channels

## Feature Reactions

### 1. Email-Based Survey Distribution with Follow-Up
- **Initial Reaction**: Positive, appreciates continuity
- **Would they use it?**: Yes, with proper communication
- **Rationale**: Values having complete communication thread for reference and context
- **Suggested Improvements**: Ensure same sender for invitation and results sharing
- **Quote**: "I would expect an email from that same recipient at some point down" the line

### 2. In-Person Survey Announcement with Email Delivery
- **Initial Reaction**: Supportive of hybrid approach
- **Would they use it?**: Yes, sees value in combining mediums
- **Rationale**: Allows for immediate context-setting while maintaining digital convenience
- **Suggested Improvements**: Clear communication that email is coming immediately
- **Additional Context**: Appreciates transparency about process

### 3. External Incentives for Survey Completion
- **Initial Reaction**: Negative, sees as counterproductive
- **Would they use it?**: Would complete for incentive but feels inauthentic
- **Rationale**: "If someone gives me something to do this, it makes it even more" inauthentic
- **Suggested Improvements**: Build intrinsic value instead: "build trust that this is gonna be useful to me in some way"
- **Quote**: "I don't think I would ever fill out a survey for incentive"

## Memorable Quotes

> "It's just a black hole. You send it down the pipe. And it's unclear what happens to the survey or whether it was worth your time filling it out."

> "I want to skip surveys because I feel somewhat inauthentic. In some way. And I think my only motivation is that seems the path if there's no other option to give feedback."

> "If you really wanted it. It would be the most authentic way to get it, to do a retro with the attendees at the very end and to devote time in the event itself to have a discussion."

> "I think it would be interesting to know if there was any action as a consequence of the results that I gave."

> "If someone gives me something to do this, it makes it even more inauthentic. Because it makes it that you have to give me something in order to fill this out."

> "Build trust that this is gonna be useful to me in some way."

> "The more information you give me, great, that's probably helpful to understand my intention."

## Behavioral Observations

- **Values authenticity over efficiency**: Consistently prioritises genuine feedback exchange over quick completion
- **Pragmatic about constraints**: Acknowledges ideal solutions while accepting practical limitations
- **Process-oriented thinker**: Focuses on communication flows and systematic approaches to feedback
- **Skeptical of surface-level engagement**: Questions motivations behind requests and looks for deeper purpose
- **Collaborative preference**: Gravitates toward discussion-based rather than isolated feedback methods
- **Quality-focused**: Prefers fewer, higher-quality interactions over frequent, shallow ones
- **Context-aware**: Considers how medium, timing, and communication style affect experience quality
- **Intrinsically motivated**: Responds better to internal value alignment than external incentives

## Follow-up Questions

1. How long typically passes between attending an event and receiving a survey invitation? Does timing affect your likelihood to respond?

2. Can you describe a specific example where you received follow-up about actions taken based on survey feedback?

3. What other feedback channels have you used for conferences that felt more authentic than surveys?

4. How do you decide between attending team retrospectives versus individual feedback for work projects?

5. What's the ideal group size for the kind of discussion-based feedback session you described?

6. Have you experienced surveys where question purpose was clearly explained? How did that change your responses?

7. What would make you trust that survey organisers "really want" the information rather than going through motions?

8. How do you currently provide feedback to your Thursday dodgeball team beyond the attendance survey?

## Next Steps

- **Mike Mitchell**: Explain to conference attendees what will be done with survey information and how it will be used

- **Mike Mitchell**: Consider implementing a retro-style discussion session for survey results at future North America meetings

- **Mike Mitchell**: Ensure survey focuses on actions that can be taken from feedback rather than just collecting responses

- **Mike Mitchell**: Investigate feasibility of group discussion format for survey completion during December conference
