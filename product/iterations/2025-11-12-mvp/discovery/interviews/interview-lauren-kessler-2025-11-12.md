# Interview: Lauren Kessler

**Date:** 2025-11-12 (16:00)
**Interviewer:** Mike Mitchell
**Persona:** Conference logistics coordinator and survey data consumer

## Participant Background

**Role**: Leading talent acquisition and people in North America for Equal Experts; responsible for all logistics and event planning for the annual conference

**Experience**: Has been a participant in similar conferences with surveys but not previously planned conferences; currently managing hiring (just completed pre-negotiation with sales candidate for potential new year hire)

**Company/Context**: Equal Experts software consultancy; handles venue selection, food, transportation logistics while other team members lead content; operates with Saturday conference format requiring personal time commitment from attendees

## Pain Points and Problem Areas

### 1. Instructions Clarity Issues
- **Quote**: "There's been a lot of people who have done some questionable things based on instructions."
- **Context**: During conference booking and logistics coordination
- **Frequency**: "So many discrepancies in the instructions"
- **Impact**:
  - Severity: Medium/High
  - Consequences: Creates extra work, confusion, potential booking errors
  - Emotional impact: Frustration with unclear root cause
- **Current Workaround**: Adding buffers to booking deadlines, trying to anticipate failure modes
- **Underlying Need**: Provide clear, actionable instructions that people will follow consistently

### 2. Communication Channel Uncertainty
- **Quote**: "What's the best way to communicate information? Is it slack? Is it email?"
- **Context**: Coordinating conference logistics and information distribution
- **Frequency**: Ongoing challenge across all communications
- **Impact**:
  - Severity: Medium
  - Consequences: Inefficient communication, missed information, responses scattered across platforms
  - Emotional impact: Uncertainty about effectiveness
- **Current Workaround**: Using multiple channels, getting responses scattered across platforms
- **Underlying Need**: Establish single, effective communication channel that reaches everyone

### 3. Lack of Community Sentiment Data
- **Quote**: "We don't have great data on how people are feeling about the E community in general."
- **Context**: Understanding employee engagement and brand connection
- **Frequency**: Ongoing gap in organizational knowledge
- **Impact**:
  - Severity: High
  - Consequences: Making decisions without understanding community sentiment, potential disconnect between company goals and employee experience
  - Emotional impact: Operating blind on critical cultural metrics
- **Current Workaround**: None - "I didn't think I was ever gonna get that data, and I was gonna have to do some trial and error"
- **Underlying Need**: Understand community engagement levels to inform event strategy

### 4. Event Planning Without Interest Data
- **Quote**: "My biggest fear is that we go after something and nobody's interested"
- **Context**: Planning future events and community activities
- **Frequency**: Every event planning decision
- **Impact**:
  - Severity: High
  - Consequences: Wasted resources, low attendance, missed opportunities
  - Emotional impact: Fear, uncertainty about resource allocation
- **Current Workaround**: Trial and error approach
- **Underlying Need**: Plan events based on demonstrated attendee interest and preferences

### 5. Free-Form Feedback Overwhelming Volume
- **Quote**: "Free flow text field with no character limit produced a lot of complaints about the venue."
- **Context**: Previous conference survey experience
- **Frequency**: Single experience but memorable
- **Impact**:
  - Severity: Medium
  - Consequences: Overwhelmed with repetitive complaints, difficult to process feedback
  - Emotional impact: Dreading feedback volume
- **Current Workaround**: Considering structured questions to limit scope
- **Underlying Need**: Get actionable feedback without being overwhelmed by repetitive complaints

## Unmet Needs

### 1. Demographic Segmentation Capability
- **Need Statement**: Raw data export with demographic fields (active/associate, client/employee, location, travel status) for custom analysis
- **Context**: Analyzing different groups' conference experiences
- **Type**: Enabling capability
- **Associated with Pain**: No - enabling new analytical capabilities
- **Priority**: Must-have for meaningful analysis
- **Success Criteria**: "I can dice it the ways that I need to… based on who's active, clients, employees versus associates"

### 2. High Survey Response Rate
- **Need Statement**: 95% completion rate from all active team members
- **Context**: Making survey data statistically meaningful
- **Type**: Quality requirement
- **Associated with Pain**: Yes - addresses lack of community sentiment data
- **Priority**: Must-have - "if I only get five people, then the data doesn't mean anything to me"
- **Success Criteria**: "95% completion or completion from all of our active team members"

### 3. Raw Data Access Over Processed Reports
- **Need Statement**: Direct spreadsheet/CSV export rather than pre-formatted charts or tables
- **Context**: Custom analysis and cross-referencing needs
- **Type**: Requirement
- **Associated with Pain**: No - preferred working method
- **Priority**: Strong preference - "I love the raw data… it's more helpful for me to get all of it"
- **Success Criteria**: Ability to slice and dice data independently

### 4. Survey Completion Within Conference Window
- **Need Statement**: Survey completion before attendees leave the conference
- **Context**: Maximizing response rate and capturing immediate feedback
- **Type**: Constraint/Requirement
- **Associated with Pain**: Yes - addresses response rate concerns
- **Priority**: High preference - "I always prefer to fill it out, like, while I'm there at the end of the day"
- **Success Criteria**: Could carve out 5-10 minutes during 5-6pm break

### 5. Budget Planning Data Before Holidays
- **Need Statement**: Survey results received before holiday break to inform 2026 planning
- **Context**: Planning calendar and budget proposals for new year
- **Type**: Timing constraint
- **Associated with Pain**: No - enabling better planning
- **Priority**: Helpful but not critical - "if you gave it to me in January, which is informed with that February calendar"
- **Success Criteria**: Data available before holidays for January calendar planning

## Aspirations & Opportunities

### 1. Structured Event Interest Ranking
- **Aspiration**: Choice ranking system where attendees drag-and-drop different conference elements in order of preference
- **Inspiration Source**: Frustration with free-form text providing unusable categorization
- **Why It Excites Them**: "That would be really helpful for me to see because then it gives me quantitative data on how people were ranking different things"
- **Uncertainty/Questions**: How to implement drag-and-drop functionality effectively
- **Exploration vs Commitment**: High interest, specific implementation vision
- **Quote**: "If I was designing the survey myself, I might ask choice rank on what was your favorite part"

### 2. Dynamic Survey Content Based on Issues
- **Aspiration**: Ability to modify survey content last-minute to address specific conference problems
- **Inspiration Source**: WiFi failure example from previous conference experience
- **Why It Excites Them**: Could acknowledge known issues while still gathering useful feedback
- **Uncertainty/Questions**: Technical feasibility and effort required
- **Exploration vs Commitment**: Interested but acknowledges "might be just too hard to ask people to do"
- **Quote**: "It almost feels better to say, did you experience an issue with wifi?"

### 3. Community Connection Metrics
- **Aspiration**: Understanding whether attendees feel part of something bigger than their individual projects
- **Inspiration Source**: Gap in organizational knowledge about employee sentiment
- **Why It Excites Them**: Could transform event planning from trial-and-error to data-driven decisions
- **Uncertainty/Questions**: How to measure sentiment effectively without bias
- **Exploration vs Commitment**: High commitment - critical for strategic planning
- **Quote**: "Ideally, the scenario isn't that they feel a part of something bigger than just the project"

## Current Workflow

### Conference Feedback Collection Planning

**Trigger**: Need to understand conference effectiveness and plan future events

**Goal**: Gather actionable data on attendee experience and preferences for future event planning

**Steps**:

1. **Previous approach (reference point)**: Wait for post-conference feedback via email
   - Tools/systems used: Email surveys, Microsoft Forms
   - Time required: Extended timeline, low response rate
   - Blockers/friction: People don't respond after leaving conference

2. **Ideal new approach**: In-conference survey completion
   - Tools/systems used: Mobile-optimized survey app
   - Time required: 5-10 minutes during scheduled break
   - Decision points: Whether to make completion mandatory for break/dinner
   - Collaboration: Coordination with conference schedule and break timing

3. **Data analysis and action planning**:
   - Tools/systems used: Raw CSV export, custom spreadsheet analysis
   - Actions taken: Segment by demographics, identify trends, propose budget allocations
   - Time required: Post-conference analysis period
   - Collaboration: Present findings to leadership team (Katie) for budget approval

**Completion Criteria**: Data analysis complete and 2026 event calendar/budget proposals submitted

**Variations**: Timeline flexible (before holidays ideal, January acceptable)

**Pain Points in Workflow**: Currently no systematic feedback collection, relying on trial-and-error

**What's Missing**: Structured data collection tool and systematic analysis process

## Feature Reactions

### 1. In-Conference Survey Completion
- **Initial Reaction**: Highly positive
- **Would they use it?**: Yes, with enthusiasm
- **Rationale**: Aligns with preference for immediate completion while experience is fresh
- **Suggested Improvements**: Integrate with conference break schedule, potentially make mandatory
- **Quote**: "I'd rather kind of leave everything at the conference. If you give me a task to do on the plane, I'm not gonna do it"

### 2. Choice Ranking Interface
- **Initial Reaction**: Very interested
- **Would they use it?**: Yes, specifically requested this feature
- **Rationale**: Provides quantitative data while avoiding overwhelming free-form text
- **Suggested Improvements**: Drag-and-drop functionality for easy ranking
- **Quote**: "That would be really helpful for me to see because then it gives me quantitative data"

### 3. Raw Data Export
- **Initial Reaction**: Strong preference
- **Would they use it?**: Essential requirement
- **Rationale**: Needs flexibility for custom demographic analysis and cross-referencing
- **Suggested Improvements**: CSV format preferred over formatted reports
- **Quote**: "I love the raw data. If you just send me the spreadsheet that Google Forms spits out, I can dice it the ways I need to"

## Memorable Quotes

> "My biggest fear is that we go after something and nobody's interested"

> "We don't have great data on how people are feeling about the E community in general. Do they feel part of something bigger, or like they're on their own little island?"

> "I love the raw data. If you just send me the spreadsheet, I can dice it the ways that I need to"

> "If you give me a task to do on the plane, I'm not gonna do it"

> "Response rate. So it needs to be something people actually respond to, because if I only get five people, the data doesn't mean anything to me"

> "There's been a lot of people who have done some questionable things based on the instructions I've sent them"

> "Before this conversation, I didn't think I was ever gonna get that data, and I was gonna have to do some trial and error to find that"

> "If you want your drink Band, you'll show me that you completed the survey"

## Behavioral Observations

- **Data-driven decision maker**: Consistently emphasizes need for quantitative data over anecdotal feedback; wants to move from trial-and-error to evidence-based planning

- **Pragmatic about implementation**: Acknowledges constraints and trade-offs while maintaining clear vision of desired outcomes

- **Quality-focused on response rates**: Understands that low participation invalidates results; willing to implement enforcement mechanisms to ensure meaningful data collection

- **Hands-on analytical approach**: Prefers raw data over processed reports; wants control over segmentation and analysis rather than pre-formatted insights

- **Time-conscious about participant burden**: Limits survey to 10 minutes maximum; understands that longer surveys reduce completion rates

- **Strategic about timing**: Thinks systematically about when people are most likely to respond (during conference vs. after departure)

- **Experience-informed**: References specific past examples to illustrate points and guide decisions

- **Operationally detail-oriented**: Considers logistics like break timing, enforcement mechanisms, and integration with conference schedule

## Follow-up Questions

1. What specific demographic splits would be most valuable for analysis beyond those mentioned (active vs associates, clients vs employees, location, travel)?
2. How would success metrics for community engagement be defined and measured over time beyond the initial conference survey?
3. What other event formats or engagement types should be tested beyond those discussed (in-person socials, brown bags, learning opportunities, UK connections, Slack activities)?
4. How should the survey handle new team member Danielle's role in future event planning and what data would be most useful for her?
5. What specific budget thresholds or approval processes exist that the survey data needs to support?
6. Are there specific questions about the booking process that would be most valuable (beyond general clarity of instructions)?
7. What level of granularity is needed for "favorability of the EE brand" measurement?
8. Should the survey differentiate between different types of networking (structured vs casual, small group vs large group)?
9. What follow-up mechanisms exist for addressing negative feedback or issues raised in surveys?

## Next Steps

- **Mike Mitchell**: Incorporate choice ranking functionality into survey design requirements
- **Mike Mitchell**: Plan survey timing integration with 5-6pm conference break schedule
- **Mike Mitchell**: Design demographic segmentation fields for data export capability
- **Mike Mitchell**: Investigate feasibility of dynamic survey content modification
- **Lauren Kessler**: Send additional survey question ideas that come to mind after the interview
- **Mike Mitchell**: Follow up on raw data export format preferences and technical requirements
